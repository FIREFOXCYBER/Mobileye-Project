{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in pairs and using the starter code -- train a neural network whose input is a cropped (81x81) color image and whose output is the probability that the center pixel of that image is part of a traffic light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics to Discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "    Any combination of convolutional, fully-connected and pooling layers is possible as long as the output is the right size. Decreasing H and W can be done with pooling or changing the strides of the convolutions.\n",
    "## Learning Rate\n",
    "    Decreasing the learning rate over time can help\n",
    "## Loss\n",
    "    What is the appropriate loss for binary classification? (sigmoid cross entropy)\n",
    "## Overfitting\n",
    "    How can we tell if our net is overfitting? If the train set loss and test set loss diverge too much\n",
    "    What can we do about it? Regularization, Data Augmentation. There are also more advanced options like batchnorm and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "######## Imports ########\n",
    "#########################\n",
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#### Neural Net Class ###\n",
    "#########################\n",
    "class TLNet:\n",
    "\n",
    "    def __init__(self, out_dir, data_dir=None, crop_size=81):\n",
    "        \n",
    "        #########################\n",
    "        #### Initialize Net #####\n",
    "        #########################\n",
    "        \n",
    "        self.out_dir = out_dir\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        self.data_dir = data_dir\n",
    "        self.crop_size = crop_size\n",
    "        # Tensorflow placeholders serve as input pipes that we can fill later with data from any dataset we\n",
    "        # wish (as long as its examples are the expected shape)\n",
    "        self.input_data = tf.placeholder(tf.uint8, shape=[None, crop_size, crop_size, 3], name=\"input_imgs\")\n",
    "        self.labels = tf.placeholder(tf.uint8, [None, 1], name=\"labels\")\n",
    "\n",
    "        self.model_out = self.model(self.input_data)\n",
    "        \n",
    "        # We use a sigmoid on the model output so that it's predictions will be between 0 and 1\n",
    "        # representing the likelihood in percentage terms that the input image IS a positive example\n",
    "        self.prediction = tf.nn.sigmoid(self.model_out, name=\"prediction\")\n",
    "        \n",
    "        self.loss = self.calc_loss(self.model_out, tf.cast(self.labels, tf.float32))\n",
    "        \n",
    "        self.opt = None\n",
    "        \n",
    "        # Where to save the checkpoint\n",
    "        self.model_path = os.path.join(self.out_dir, \"TLNet.ckpt\")\n",
    "\n",
    "\n",
    "    def model(self, images):\n",
    "        \n",
    "        #########################\n",
    "        ##### Architecture ######\n",
    "        #########################\n",
    "        \n",
    "        # Cast uint8 images to float32 and normalize so their values are between 0 and 1\n",
    "        # Normalization is very important in training neural nets\n",
    "        images = tf.cast(images, tf.float32)\n",
    "        images *= (1. / 256)\n",
    "        size=2\n",
    "        size2=2\n",
    "        \n",
    "        # Layers of the net\n",
    "        conv1 = self.conv_layer(images, 12*size, 'conv1', kernel=5, stride=1)\n",
    "        conv2 = self.conv_layer(conv1, 24*size, 'conv2', kernel=5, stride=2*size2)\n",
    "        conv3 = self.conv_layer(conv2, 24*size, 'conv3', kernel=3, stride=1)\n",
    "        conv4 = self.conv_layer(conv3, 48*size, 'conv4', kernel=3, stride=2*size2)\n",
    "        conv5 = self.conv_layer(conv4, 48*size, 'conv5', kernel=3, stride=1)\n",
    "#         conv6 = self.conv_layer(conv5, 96*size, 'conv6', kernel=3, stride=2*size2)\n",
    "#         conv7 = self.conv_layer(conv6, 96*size, 'conv7', kernel=3, stride=1)\n",
    "#         conv8 = self.conv_layer(conv7, 192*size, 'conv8', kernel=3, stride=2*size2)\n",
    "        conv9 = self.conv_layer(conv5, 64*size, 'conv9', kernel=3, stride=1)\n",
    "        conv10 = self.conv_layer(conv9, 24*size, 'conv10', kernel=3, stride=1)\n",
    "                \n",
    "        fc11 = self.fc_layer(conv10, output_neurons=48, name='fc11', doRelu=True)\n",
    "        fc12 = self.fc_layer(fc11, output_neurons=1, name='fc12', doRelu=False)\n",
    "    \n",
    "        output = tf.identity(fc12, name='output')\n",
    "\n",
    "        return output\n",
    "\n",
    "    def calc_loss(self, model_out, label):\n",
    "        \n",
    "        #########################\n",
    "        ######### Loss ##########\n",
    "        #########################\n",
    "        \n",
    "        # Sigmoid cross entropy is the go-to loss for yes/no classification tasks\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_out, labels=label))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def save(self, sess, model_path):\n",
    "        \n",
    "        # Save the current model\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "\n",
    "    def restore(self, sess, model_path):\n",
    "        \n",
    "        # Restore previously trained model\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "\n",
    "    def train(self, iters, learning_rate, batch_size, restore=False, ckpt_path=None):\n",
    "        \n",
    "        #########################\n",
    "        ####### Train Net #######\n",
    "        #########################\n",
    "        \n",
    "        # Prep data\n",
    "                \n",
    "        dataset_train = self.prep_data(os.path.join(self.data_dir, 'train', 'data1.bin'), \n",
    "                                 os.path.join(self.data_dir, 'train', 'labels1.bin'), \n",
    "                                 batch_size=batch_size, crop_size=self.crop_size)\n",
    "        dataset_val = self.prep_data(os.path.join(self.data_dir, 'val', 'data1.bin'), \n",
    "                                os.path.join(self.data_dir, 'val', 'labels1.bin'), \n",
    "                                batch_size=batch_size, crop_size=self.crop_size)\n",
    "\n",
    "        train_iterator = tf.data.Iterator.from_structure(dataset_train.output_types, dataset_train.output_shapes)\n",
    "        batch_of_train_images = train_iterator.get_next()\n",
    "        train_iterator = train_iterator.make_initializer(dataset_train)\n",
    "\n",
    "        val_iterator = tf.data.Iterator.from_structure(dataset_val.output_types, dataset_val.output_shapes)\n",
    "        batch_of_val_images = val_iterator.get_next()\n",
    "        val_iterator = val_iterator.make_initializer(dataset_val)\n",
    "        \n",
    "        if not self.opt:\n",
    "            \n",
    "            # Define optimizer\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize variables and data iterators\n",
    "            sess.run(train_iterator)\n",
    "            sess.run(val_iterator)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            if restore:\n",
    "                # Restore trained weights and biases from checkpoint\n",
    "                self.restore(sess, ckpt_path)\n",
    "\n",
    "                print (\"Resuming from previously saved checkpoint ...\")\n",
    "                \n",
    "            # Define losses and accuracy\n",
    "            train_loss = 0.\n",
    "            val_loss = 0.\n",
    "            val_accuracy = 0.\n",
    "\n",
    "            # Train\n",
    "            for i in range(iters):\n",
    "\n",
    "                try:\n",
    "                    # Get a batch of images and labels from the training data generator\n",
    "                    train_batch = sess.run(batch_of_train_images)\n",
    "                    train_images = train_batch[0]\n",
    "                    train_labels = train_batch[1]\n",
    "                    \n",
    "                    # Run the optimizer (this is where the real training is occurring)\n",
    "                    _, out_loss = sess.run([self.opt, self.loss], feed_dict=\n",
    "                                           {self.input_data: train_images, self.labels: train_labels})\n",
    "                    \n",
    "                    # Update the loss average over all of training\n",
    "                    train_loss += np.mean(out_loss)\n",
    "\n",
    "                    if (i+1) % 10 == 0:\n",
    "                        # Print loss statement\n",
    "                        print (\"Iter: \" + str(i+1) + \", Current train loss: %f\" % (train_loss / (i+1)))\n",
    "\n",
    "                    if (i+1) % 100 == 0:\n",
    "                        # Save checkpoint\n",
    "                        print (\"Saving checkpoint\")\n",
    "                        save_path = self.save(sess, self.model_path)\n",
    "\n",
    "                    if (i+1) % 100 == 0:\n",
    "                        # Evaluate the net on the validation set\n",
    "                        print (\"Performing Evaluation\")\n",
    "                        \n",
    "                        val_batch = sess.run(batch_of_val_images)\n",
    "                        val_images = val_batch[0]\n",
    "                        val_labels = val_batch[1]\n",
    "\n",
    "                        out_prediction, out_val_loss = sess.run([self.prediction, self.loss],\n",
    "                                               feed_dict={self.input_data: val_images, self.labels: val_labels})\n",
    "                        \n",
    "                        val_loss += np.mean(out_val_loss)\n",
    "                        print (\"Current loss on val set: %f\" % (val_loss / ((i+1) / 100.)))\n",
    "                        \n",
    "                        val_accuracy += np.mean(np.round(out_prediction) == val_labels)\n",
    "                        print (\"Current accuracy on val set (percent of examples labeled correctly): \" + str(float(val_accuracy / ((i+1) / 100))))\n",
    "\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "\n",
    "            print (\"Model saved at \" + save_path)\n",
    "\n",
    "    def evaluate(self, ckpt_path, batch_size, crop_size=81):\n",
    "        \n",
    "        #########################\n",
    "        ## Evaluate Trained Net #\n",
    "        #########################\n",
    "                \n",
    "        dataset_val = self.prep_data(os.path.join(self.data_dir, 'val', 'data1.bin'), os.path.join(self.data_dir, 'val', 'labels1.bin'), batch_size=batch_size, crop_size=self.crop_size)\n",
    "\n",
    "        val_iterator = tf.data.Iterator.from_structure(dataset_val.output_types, dataset_val.output_shapes)\n",
    "\n",
    "        batch_of_images = val_iterator.get_next()\n",
    "\n",
    "        input_images_test = batch_of_images[0]\n",
    "        input_labels_test = batch_of_images[1]\n",
    "\n",
    "        val_iterator = val_iterator.make_initializer(dataset_val)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize\n",
    "            sess.run(val_iterator)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            self.restore(sess, ckpt_path)\n",
    "\n",
    "            batch_out = sess.run(batch_of_images)\n",
    "            val_images = batch_out[0]\n",
    "            val_labels = batch_out[1]\n",
    "\n",
    "            print (\"resuming from previously saved checkpoint\")\n",
    "\n",
    "            predict_result, out_loss = sess.run([self.prediction, self.loss], feed_dict={self.input_data: val_images, self.labels: val_labels})\n",
    "\n",
    "            print (\"Loss on prediction was:\")\n",
    "            print (np.mean(out_loss))\n",
    "            print (\"Prediction was:\")\n",
    "            print (np.squeeze(predict_result))\n",
    "            print (\"Label was:\")\n",
    "            print (np.squeeze(val_labels))\n",
    "            print (\"Accuracy: %f\" % np.mean(np.round(predict_result) == val_labels))\n",
    "    \n",
    "    def predict(self, ckpt_path, img, crop_size=81):\n",
    "        \n",
    "        # FUNCTION\n",
    "        # Given an image and a checkpoint path, restore a trained model and run it on a single image\n",
    "\n",
    "        # INPUT\n",
    "        # **ckpt_path: filepath to model checkpoint\n",
    "        # **img: numpy array of shape (crop_size, crop_size, 3) and dtype uint8\n",
    "\n",
    "        # OUTPUT\n",
    "        # **prediction between 0 and 1 of how likely it is to be a traffic light\n",
    "\n",
    "        # Normalize the image, convert it to float32 and reshape it to be a single batch\n",
    "        \n",
    "#         img = img.astype(np.float32) / 256.\n",
    "        img = img.reshape(1,crop_size,crop_size,3)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Initialize\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            self.restore(sess, ckpt_path)\n",
    "\n",
    "            print (\"resuming from previously saved checkpoint\")\n",
    "\n",
    "            # Run inference (note that the session does not need to be fed a label because\n",
    "            # we are not calculating the loss or running the optimizer)\n",
    "            predict_result = sess.run([self.prediction], feed_dict={self.input_data: img})\n",
    "\n",
    "            return float(np.squeeze(predict_result))\n",
    "\n",
    "    \n",
    "    #########################\n",
    "    ######## Layers #########\n",
    "    #########################\n",
    "    \n",
    "    def fc_layer(self, input_tensor, output_neurons, name, doRelu=True):\n",
    "        with tf.variable_scope(name):\n",
    "                          \n",
    "            shape = input_tensor.get_shape().as_list()\n",
    "            dim = 1\n",
    "            for d in shape[1:]:\n",
    "                dim *= d\n",
    "            x = tf.reshape(input_tensor, [-1, dim])\n",
    "                          \n",
    "            activation = None\n",
    "            if doRelu:\n",
    "                activation = tf.nn.relu\n",
    "            fc = tf.layers.dense(x, output_neurons, activation=activation)\n",
    "\n",
    "            return fc\n",
    "\n",
    "\n",
    "    def conv_layer(self, input_tensor, output_channels, name, kernel=3, stride=1, doRelu=True):\n",
    "        with tf.variable_scope(name):\n",
    "            strides = (stride,stride)\n",
    "            conv = tf.layers.conv2d(input_tensor, filters=output_channels, kernel_size=kernel, strides=strides, padding='SAME', data_format='channels_last', kernel_initializer=tf.keras.initializers.glorot_normal())\n",
    "\n",
    "            if doRelu:\n",
    "                conv = tf.nn.relu(conv)\n",
    "\n",
    "            return conv\n",
    "\n",
    "    def avg_pool(self, input_tensor, name, stride=2):\n",
    "        return tf.nn.avg_pool(input_tensor, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "\n",
    "    def max_pool(self, input_tensor, name, stride=2):\n",
    "        return tf.nn.max_pool(input_tensor, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)\n",
    "\n",
    "    #########################\n",
    "    ##### Import Data #######\n",
    "    #########################    \n",
    "\n",
    "    def prep_data(self, g_data, g_label, batch_size, crop_size=81):\n",
    "\n",
    "        # FUNCTION\n",
    "        # Given binary files, imports data as tensorflow dataset objects\n",
    "\n",
    "        # INPUT\n",
    "        # **g_data: filepath to binary data file\n",
    "        # **g_label: filepath to binary label file\n",
    "        # **batch_size: the number of examples the dataset will supply at each iteration\n",
    "        # **crop_size: size of the input image (assumed to be square)\n",
    "\n",
    "        # OUTPUT\n",
    "        # **tensorflow dataset object\n",
    "\n",
    "        filename_dataset = tf.data.Dataset.list_files(g_data)\n",
    "\n",
    "        image_dataset = filename_dataset.map(lambda x: tf.decode_raw(tf.read_file(x), tf.uint8))\n",
    "        image_dataset = image_dataset.map(lambda x: tf.reshape(x, [-1, crop_size, crop_size, 3]))\n",
    "        image_dataset = image_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
    "        image_dataset = image_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        filename_dataset = tf.data.Dataset.list_files(g_label)\n",
    "\n",
    "        label_dataset = filename_dataset.map(lambda x: tf.decode_raw(tf.read_file(x), tf.uint8))\n",
    "        label_dataset = label_dataset.map(lambda x: tf.reshape(x, [-1, 1]))\n",
    "        label_dataset = label_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
    "        label_dataset = label_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        full_dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "        full_dataset = full_dataset.prefetch(buffer_size=batch_size*5)\n",
    "        full_dataset = full_dataset.shuffle(buffer_size=batch_size*10)\n",
    "        full_dataset = full_dataset.repeat()\n",
    "\n",
    "        return full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-07676c44f38d>:284: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From c:\\users\\rent\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-07676c44f38d>:276: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From c:\\users\\rent\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_dir = r'C:\\Users\\RENT\\m\\CityScapes\\data_dir'\n",
    "out_dir = r'C:\\Users\\RENT\\m\\CityScapes\\output'\n",
    "ckpt_path = r'C:\\Users\\RENT\\m\\CityScapes\\output\\TLNet.ckpt'\n",
    "model = TLNet(data_dir=data_dir, out_dir=out_dir, crop_size=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\rent\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\autograph\\converters\\directives.py:119: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-07676c44f38d>:107: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From <ipython-input-2-07676c44f38d>:107: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From c:\\users\\rent\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From c:\\users\\rent\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From c:\\users\\rent\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "Iter: 10, Current train loss: 0.663870\n",
      "Iter: 20, Current train loss: 0.649088\n",
      "Iter: 30, Current train loss: 0.634894\n",
      "Iter: 40, Current train loss: 0.613644\n",
      "Iter: 50, Current train loss: 0.607394\n",
      "Iter: 60, Current train loss: 0.611693\n",
      "Iter: 70, Current train loss: 0.609833\n",
      "Iter: 80, Current train loss: 0.599338\n",
      "Iter: 90, Current train loss: 0.588259\n",
      "Iter: 100, Current train loss: 0.584676\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.420714\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7708333333333334\n",
      "Iter: 110, Current train loss: 0.583886\n",
      "Iter: 120, Current train loss: 0.575594\n",
      "Iter: 130, Current train loss: 0.566387\n",
      "Iter: 140, Current train loss: 0.562402\n",
      "Iter: 150, Current train loss: 0.554618\n",
      "Iter: 160, Current train loss: 0.548206\n",
      "Iter: 170, Current train loss: 0.548438\n",
      "Iter: 180, Current train loss: 0.543572\n",
      "Iter: 190, Current train loss: 0.539609\n",
      "Iter: 200, Current train loss: 0.536679\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.464554\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7708333333333334\n",
      "Iter: 210, Current train loss: 0.535282\n",
      "Iter: 220, Current train loss: 0.532891\n",
      "Iter: 230, Current train loss: 0.530575\n",
      "Iter: 240, Current train loss: 0.527862\n",
      "Iter: 250, Current train loss: 0.523691\n",
      "Iter: 260, Current train loss: 0.520415\n",
      "Iter: 270, Current train loss: 0.518635\n",
      "Iter: 280, Current train loss: 0.517263\n",
      "Iter: 290, Current train loss: 0.516865\n",
      "Iter: 300, Current train loss: 0.514645\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.469745\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7569444444444445\n",
      "Iter: 310, Current train loss: 0.510048\n",
      "Iter: 320, Current train loss: 0.508623\n",
      "Iter: 330, Current train loss: 0.507960\n",
      "Iter: 340, Current train loss: 0.505197\n",
      "Iter: 350, Current train loss: 0.502964\n",
      "Iter: 360, Current train loss: 0.503286\n",
      "Iter: 370, Current train loss: 0.501078\n",
      "Iter: 380, Current train loss: 0.498005\n",
      "Iter: 390, Current train loss: 0.496087\n",
      "Iter: 400, Current train loss: 0.495054\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.494609\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.734375\n",
      "Iter: 410, Current train loss: 0.493459\n",
      "Iter: 420, Current train loss: 0.491080\n",
      "Iter: 430, Current train loss: 0.489767\n",
      "Iter: 440, Current train loss: 0.488779\n",
      "Iter: 450, Current train loss: 0.487491\n",
      "Iter: 460, Current train loss: 0.484119\n",
      "Iter: 470, Current train loss: 0.482047\n",
      "Iter: 480, Current train loss: 0.478438\n",
      "Iter: 490, Current train loss: 0.474635\n",
      "Iter: 500, Current train loss: 0.473002\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.475820\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7375\n",
      "Iter: 510, Current train loss: 0.470385\n",
      "Iter: 520, Current train loss: 0.468258\n",
      "Iter: 530, Current train loss: 0.465312\n",
      "Iter: 540, Current train loss: 0.462559\n",
      "Iter: 550, Current train loss: 0.461573\n",
      "Iter: 560, Current train loss: 0.460831\n",
      "Iter: 570, Current train loss: 0.459926\n",
      "Iter: 580, Current train loss: 0.458236\n",
      "Iter: 590, Current train loss: 0.456389\n",
      "Iter: 600, Current train loss: 0.455798\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.469670\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.75\n",
      "Iter: 610, Current train loss: 0.453198\n",
      "Iter: 620, Current train loss: 0.452144\n",
      "Iter: 630, Current train loss: 0.450558\n",
      "Iter: 640, Current train loss: 0.448535\n",
      "Iter: 650, Current train loss: 0.447365\n",
      "Iter: 660, Current train loss: 0.445597\n",
      "Iter: 670, Current train loss: 0.444783\n",
      "Iter: 680, Current train loss: 0.443917\n",
      "Iter: 690, Current train loss: 0.441130\n",
      "Iter: 700, Current train loss: 0.439735\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.426195\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.7827380952380952\n",
      "Iter: 710, Current train loss: 0.438478\n",
      "Iter: 720, Current train loss: 0.437703\n",
      "Iter: 730, Current train loss: 0.436687\n",
      "Iter: 740, Current train loss: 0.435808\n",
      "Iter: 750, Current train loss: 0.434811\n",
      "Iter: 760, Current train loss: 0.433731\n",
      "Iter: 770, Current train loss: 0.433320\n",
      "Iter: 780, Current train loss: 0.431325\n",
      "Iter: 790, Current train loss: 0.429957\n",
      "Iter: 800, Current train loss: 0.428315\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.396391\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8020833333333334\n",
      "Iter: 810, Current train loss: 0.426491\n",
      "Iter: 820, Current train loss: 0.424697\n",
      "Iter: 830, Current train loss: 0.423051\n",
      "Iter: 840, Current train loss: 0.421118\n",
      "Iter: 850, Current train loss: 0.419488\n",
      "Iter: 860, Current train loss: 0.418148\n",
      "Iter: 870, Current train loss: 0.417576\n",
      "Iter: 880, Current train loss: 0.416169\n",
      "Iter: 890, Current train loss: 0.414702\n",
      "Iter: 900, Current train loss: 0.413386\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.380265\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8125\n",
      "Iter: 910, Current train loss: 0.411786\n",
      "Iter: 920, Current train loss: 0.410343\n",
      "Iter: 930, Current train loss: 0.408231\n",
      "Iter: 940, Current train loss: 0.406701\n",
      "Iter: 950, Current train loss: 0.404935\n",
      "Iter: 960, Current train loss: 0.403370\n",
      "Iter: 970, Current train loss: 0.402999\n",
      "Iter: 980, Current train loss: 0.401890\n",
      "Iter: 990, Current train loss: 0.400952\n",
      "Iter: 1000, Current train loss: 0.399486\n",
      "Saving checkpoint\n",
      "Performing Evaluation\n",
      "Current loss on val set: 0.375422\n",
      "Current accuracy on val set (percent of examples labeled correctly): 0.8166666666666667\n",
      "Model saved at C:\\Users\\RENT\\m\\CityScapes\\output\\TLNet.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train(self, iters, learning_rate, batch_size, restore=False, ckpt_path=None):\n",
    "model.train(1000, .0005, 24*2, restore=False, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\RENT\\m\\CityScapes\\output\\TLNet.ckpt\n",
      "resuming from previously saved checkpoint\n",
      "Loss on prediction was:\n",
      "0.32579038\n",
      "Prediction was:\n",
      "[9.94965792e-01 3.30614448e-01 8.69884610e-01 1.68733686e-01\n",
      " 9.78450954e-01 1.46060109e-01 6.25239193e-01 8.78840983e-02\n",
      " 9.52152789e-01 3.78055423e-01 9.48817968e-01 6.73235655e-01\n",
      " 6.55926764e-01 1.59432560e-01 9.95313764e-01 5.50065041e-02\n",
      " 9.80191588e-01 2.79084742e-02 9.78257716e-01 2.67519057e-02\n",
      " 9.95723605e-01 9.12732780e-02 8.96021366e-01 2.21678853e-01\n",
      " 2.74720609e-01 1.62198126e-01 1.65425599e-01 2.83115804e-01\n",
      " 9.57064807e-01 3.37624431e-01 1.96381807e-02 3.27995002e-01\n",
      " 7.30727375e-01 1.86159015e-02 7.75111139e-01 2.51118749e-01\n",
      " 5.52193224e-01 8.28776956e-02 9.90196109e-01 1.28346354e-01\n",
      " 8.55542302e-01 8.05739760e-01 4.02074337e-01 2.11368293e-01\n",
      " 9.95648026e-01 4.98700440e-02 9.95713770e-01 7.74019718e-01\n",
      " 9.91321445e-01 2.35939026e-01 9.99160647e-01 1.00343019e-01\n",
      " 9.92553890e-01 2.51507699e-01 9.99639034e-01 2.74814069e-01\n",
      " 9.99841869e-01 7.34631479e-01 9.92526591e-01 2.86988735e-01\n",
      " 9.96669531e-01 4.55420882e-01 9.24405813e-01 1.89432859e-01\n",
      " 9.99944687e-01 1.41529202e-01 9.64170098e-01 4.82683778e-02\n",
      " 9.99416351e-01 1.28516018e-01 9.99588370e-01 5.00684559e-01\n",
      " 9.99637187e-01 5.24083138e-01 7.61367917e-01 9.31036592e-01\n",
      " 8.72022390e-01 3.69088054e-01 9.99283910e-01 3.22810650e-01\n",
      " 4.58089352e-01 2.04876184e-01 9.85917270e-01 3.76128823e-01\n",
      " 9.44557190e-01 7.85580277e-02 9.99938369e-01 2.49416500e-01\n",
      " 9.99735832e-01 1.20726049e-01 9.99805868e-01 6.43489540e-01\n",
      " 9.13737178e-01 7.74709582e-02 9.00247693e-01 1.11638814e-01\n",
      " 9.71130490e-01 1.14860594e-01 3.95820916e-01 3.63860369e-01\n",
      " 9.54536915e-01 5.05835950e-01 9.95287418e-01 1.72515094e-01\n",
      " 9.75290537e-01 2.16623455e-01 9.96085525e-01 9.74954128e-01\n",
      " 3.96992892e-01 8.32739115e-01 9.97472644e-01 2.02308446e-01\n",
      " 9.84947205e-01 5.27318418e-02 9.96746182e-01 2.58967578e-01\n",
      " 9.98920441e-01 6.74891114e-01 9.71037626e-01 4.15293097e-01\n",
      " 9.93061781e-01 1.12216741e-01 7.04101920e-01 1.64932519e-01\n",
      " 7.94379473e-01 2.08010882e-01 9.68798697e-01 4.00489241e-01\n",
      " 9.66414332e-01 6.83576822e-01 8.85939240e-01 1.80098563e-01\n",
      " 9.97762442e-01 3.30157995e-01 9.94431734e-01 1.32089496e-01\n",
      " 9.99648571e-01 8.95069361e-01 9.86059248e-01 1.28003240e-01\n",
      " 8.60921025e-01 4.40562963e-01 6.77416980e-01 3.54844928e-02\n",
      " 8.09215307e-01 7.09424615e-02 5.39822519e-01 5.01984298e-01\n",
      " 9.90965128e-01 6.10795617e-03 9.92920935e-01 4.96214628e-03\n",
      " 9.89448309e-01 2.25414634e-01 9.87553895e-01 5.73007166e-02\n",
      " 9.95347142e-01 3.84159684e-02 7.69013584e-01 4.26033139e-03\n",
      " 9.99556184e-01 8.39719176e-03 9.18677628e-01 5.19461453e-01\n",
      " 9.93968606e-01 2.18670666e-02 6.27929091e-01 1.09520465e-01\n",
      " 9.97533917e-01 4.30557638e-01 9.30424213e-01 3.55783015e-01\n",
      " 2.92881072e-01 2.62645185e-02 3.06891680e-01 2.78460681e-01\n",
      " 9.08840358e-01 8.72011065e-01 2.32216775e-01 2.79083133e-01\n",
      " 9.99726593e-01 2.36368775e-02 9.98939991e-01 9.70187783e-03\n",
      " 7.25246310e-01 9.47226584e-02 3.51070613e-01 3.19088221e-01\n",
      " 7.18834937e-01 1.04672909e-02 9.33149338e-01 6.54411316e-03\n",
      " 7.95008600e-01 6.41554594e-03 9.99568105e-01 3.79601628e-01\n",
      " 8.56858969e-01 4.16874886e-03 9.89185035e-01 6.87748194e-04]\n",
      "Label was:\n",
      "[1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0]\n",
      "Accuracy: 0.860000\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(ckpt_path=ckpt_path, batch_size=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\RENT\\m\\CityScapes\\output\\TLNet.ckpt\n",
      "resuming from previously saved checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13355004787445068"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_image = np.zeros((81,81,3), dtype=np.uint8)\n",
    "model.predict(ckpt_path, fake_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
